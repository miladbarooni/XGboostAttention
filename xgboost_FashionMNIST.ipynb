{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:20<00:00, 1318475.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 299185.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:04<00:00, 887451.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 25791.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train data\n",
    "train_data_iter = iter(trainloader)\n",
    "train_images, train_labels = next(train_data_iter)\n",
    "\n",
    "# Extract test data\n",
    "test_data_iter = iter(testloader)\n",
    "test_images, test_labels = next(test_data_iter)\n",
    "\n",
    "# Reshape and convert to numpy\n",
    "train_images = train_images.view(-1, 28*28).numpy()\n",
    "train_labels = train_labels.numpy()\n",
    "\n",
    "test_images = test_images.view(-1, 28*28).numpy()\n",
    "test_labels = test_labels.numpy()\n",
    "\n",
    "# Convert labels to 1D array\n",
    "train_labels = train_labels.ravel()\n",
    "test_labels = test_labels.ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_images[10].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:1.97905\n",
      "[1]\teval-mlogloss:1.76250\n",
      "[2]\teval-mlogloss:1.59738\n",
      "[3]\teval-mlogloss:1.46382\n",
      "[4]\teval-mlogloss:1.35261\n",
      "[5]\teval-mlogloss:1.25705\n",
      "[6]\teval-mlogloss:1.17460\n",
      "[7]\teval-mlogloss:1.10158\n",
      "[8]\teval-mlogloss:1.03764\n",
      "[9]\teval-mlogloss:0.98030\n",
      "[10]\teval-mlogloss:0.92878\n",
      "[11]\teval-mlogloss:0.88265\n",
      "[12]\teval-mlogloss:0.84076\n",
      "[13]\teval-mlogloss:0.80278\n",
      "[14]\teval-mlogloss:0.76862\n",
      "[15]\teval-mlogloss:0.73791\n",
      "[16]\teval-mlogloss:0.70983\n",
      "[17]\teval-mlogloss:0.68368\n",
      "[18]\teval-mlogloss:0.66008\n",
      "[19]\teval-mlogloss:0.63848\n",
      "[20]\teval-mlogloss:0.61822\n",
      "[21]\teval-mlogloss:0.59986\n",
      "[22]\teval-mlogloss:0.58295\n",
      "[23]\teval-mlogloss:0.56687\n",
      "[24]\teval-mlogloss:0.55212\n",
      "[25]\teval-mlogloss:0.53844\n",
      "[26]\teval-mlogloss:0.52570\n",
      "[27]\teval-mlogloss:0.51412\n",
      "[28]\teval-mlogloss:0.50294\n",
      "[29]\teval-mlogloss:0.49246\n",
      "[30]\teval-mlogloss:0.48276\n",
      "[31]\teval-mlogloss:0.47372\n",
      "[32]\teval-mlogloss:0.46506\n",
      "[33]\teval-mlogloss:0.45730\n",
      "[34]\teval-mlogloss:0.44981\n",
      "[35]\teval-mlogloss:0.44300\n",
      "[36]\teval-mlogloss:0.43672\n",
      "[37]\teval-mlogloss:0.43066\n",
      "[38]\teval-mlogloss:0.42517\n",
      "[39]\teval-mlogloss:0.41975\n",
      "[40]\teval-mlogloss:0.41509\n",
      "[41]\teval-mlogloss:0.41051\n",
      "[42]\teval-mlogloss:0.40584\n",
      "[43]\teval-mlogloss:0.40145\n",
      "[44]\teval-mlogloss:0.39781\n",
      "[45]\teval-mlogloss:0.39429\n",
      "[46]\teval-mlogloss:0.39040\n",
      "[47]\teval-mlogloss:0.38729\n",
      "[48]\teval-mlogloss:0.38414\n",
      "[49]\teval-mlogloss:0.38103\n",
      "[50]\teval-mlogloss:0.37772\n",
      "[51]\teval-mlogloss:0.37496\n",
      "[52]\teval-mlogloss:0.37253\n",
      "[53]\teval-mlogloss:0.37005\n",
      "[54]\teval-mlogloss:0.36770\n",
      "[55]\teval-mlogloss:0.36543\n",
      "[56]\teval-mlogloss:0.36332\n",
      "[57]\teval-mlogloss:0.36120\n",
      "[58]\teval-mlogloss:0.35934\n",
      "[59]\teval-mlogloss:0.35738\n",
      "[60]\teval-mlogloss:0.35577\n",
      "[61]\teval-mlogloss:0.35408\n",
      "[62]\teval-mlogloss:0.35216\n",
      "[63]\teval-mlogloss:0.35059\n",
      "[64]\teval-mlogloss:0.34880\n",
      "[65]\teval-mlogloss:0.34707\n",
      "[66]\teval-mlogloss:0.34524\n",
      "[67]\teval-mlogloss:0.34380\n",
      "[68]\teval-mlogloss:0.34263\n",
      "[69]\teval-mlogloss:0.34133\n",
      "[70]\teval-mlogloss:0.33983\n",
      "[71]\teval-mlogloss:0.33862\n",
      "[72]\teval-mlogloss:0.33735\n",
      "[73]\teval-mlogloss:0.33614\n",
      "[74]\teval-mlogloss:0.33488\n",
      "[75]\teval-mlogloss:0.33349\n",
      "[76]\teval-mlogloss:0.33231\n",
      "[77]\teval-mlogloss:0.33119\n",
      "[78]\teval-mlogloss:0.33014\n",
      "[79]\teval-mlogloss:0.32937\n",
      "[80]\teval-mlogloss:0.32835\n",
      "[81]\teval-mlogloss:0.32758\n",
      "[82]\teval-mlogloss:0.32668\n",
      "[83]\teval-mlogloss:0.32569\n",
      "[84]\teval-mlogloss:0.32473\n",
      "[85]\teval-mlogloss:0.32372\n",
      "[86]\teval-mlogloss:0.32285\n",
      "[87]\teval-mlogloss:0.32203\n",
      "[88]\teval-mlogloss:0.32122\n",
      "[89]\teval-mlogloss:0.32060\n",
      "[90]\teval-mlogloss:0.31951\n",
      "[91]\teval-mlogloss:0.31874\n",
      "[92]\teval-mlogloss:0.31813\n",
      "[93]\teval-mlogloss:0.31730\n",
      "[94]\teval-mlogloss:0.31631\n",
      "[95]\teval-mlogloss:0.31568\n",
      "[96]\teval-mlogloss:0.31505\n",
      "[97]\teval-mlogloss:0.31432\n",
      "[98]\teval-mlogloss:0.31369\n",
      "[99]\teval-mlogloss:0.31299\n"
     ]
    }
   ],
   "source": [
    "# Convert to DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(train_images, label=train_labels)\n",
    "dtest = xgb.DMatrix(test_images, label=test_labels)\n",
    "\n",
    "# Set up parameters for XGBoost\n",
    "param = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 10,\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_round = 100\n",
    "evallist  = [(dtrain, 'eval'), (dtest, 'eval')]\n",
    "bst = xgb.train(param, dtrain, num_round, evals=evallist, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.35%\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, preds)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.12%\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "preds = bst.predict(dtrain)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(train_labels, preds)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:2.05896\n",
      "[1]\teval-mlogloss:1.86858\n",
      "[2]\teval-mlogloss:1.70350\n",
      "[3]\teval-mlogloss:1.57129\n",
      "[4]\teval-mlogloss:1.45732\n",
      "[5]\teval-mlogloss:1.35363\n",
      "[6]\teval-mlogloss:1.26535\n",
      "[7]\teval-mlogloss:1.18721\n",
      "[8]\teval-mlogloss:1.11161\n",
      "[9]\teval-mlogloss:1.05024\n",
      "[10]\teval-mlogloss:0.99268\n",
      "[11]\teval-mlogloss:0.94026\n",
      "[12]\teval-mlogloss:0.88976\n",
      "[13]\teval-mlogloss:0.84618\n",
      "[14]\teval-mlogloss:0.80575\n",
      "[15]\teval-mlogloss:0.76992\n",
      "[16]\teval-mlogloss:0.73464\n",
      "[17]\teval-mlogloss:0.70471\n",
      "[18]\teval-mlogloss:0.67519\n",
      "[19]\teval-mlogloss:0.64880\n",
      "[20]\teval-mlogloss:0.62395\n",
      "[21]\teval-mlogloss:0.60184\n",
      "[22]\teval-mlogloss:0.58073\n",
      "[23]\teval-mlogloss:0.56146\n",
      "[24]\teval-mlogloss:0.54318\n",
      "[25]\teval-mlogloss:0.52603\n",
      "[26]\teval-mlogloss:0.50838\n",
      "[27]\teval-mlogloss:0.49399\n",
      "[28]\teval-mlogloss:0.48030\n",
      "[29]\teval-mlogloss:0.46635\n",
      "[30]\teval-mlogloss:0.45457\n",
      "[31]\teval-mlogloss:0.44269\n",
      "[32]\teval-mlogloss:0.43191\n",
      "[33]\teval-mlogloss:0.42062\n",
      "[34]\teval-mlogloss:0.41007\n",
      "[35]\teval-mlogloss:0.40110\n",
      "[36]\teval-mlogloss:0.39208\n",
      "[37]\teval-mlogloss:0.38290\n",
      "[38]\teval-mlogloss:0.37501\n",
      "[39]\teval-mlogloss:0.36760\n",
      "[40]\teval-mlogloss:0.36046\n",
      "[41]\teval-mlogloss:0.35347\n",
      "[42]\teval-mlogloss:0.34676\n",
      "[43]\teval-mlogloss:0.34033\n",
      "[44]\teval-mlogloss:0.33438\n",
      "[45]\teval-mlogloss:0.32890\n",
      "[46]\teval-mlogloss:0.32373\n",
      "[47]\teval-mlogloss:0.31854\n",
      "[48]\teval-mlogloss:0.31405\n",
      "[49]\teval-mlogloss:0.30879\n",
      "[50]\teval-mlogloss:0.30427\n",
      "[51]\teval-mlogloss:0.30036\n",
      "[52]\teval-mlogloss:0.29649\n",
      "[53]\teval-mlogloss:0.29202\n",
      "[54]\teval-mlogloss:0.28805\n",
      "[55]\teval-mlogloss:0.28472\n",
      "[56]\teval-mlogloss:0.28163\n",
      "[57]\teval-mlogloss:0.27861\n",
      "[58]\teval-mlogloss:0.27553\n",
      "[59]\teval-mlogloss:0.27277\n",
      "[60]\teval-mlogloss:0.26920\n",
      "[61]\teval-mlogloss:0.26703\n",
      "[62]\teval-mlogloss:0.26449\n",
      "[63]\teval-mlogloss:0.26238\n",
      "[64]\teval-mlogloss:0.25991\n",
      "[65]\teval-mlogloss:0.25784\n",
      "[66]\teval-mlogloss:0.25507\n",
      "[67]\teval-mlogloss:0.25293\n",
      "[68]\teval-mlogloss:0.25153\n",
      "[69]\teval-mlogloss:0.24943\n",
      "[70]\teval-mlogloss:0.24777\n",
      "[71]\teval-mlogloss:0.24579\n",
      "[72]\teval-mlogloss:0.24356\n",
      "[73]\teval-mlogloss:0.24133\n",
      "[74]\teval-mlogloss:0.23962\n",
      "[75]\teval-mlogloss:0.23761\n",
      "[76]\teval-mlogloss:0.23600\n",
      "[77]\teval-mlogloss:0.23404\n",
      "[78]\teval-mlogloss:0.23239\n",
      "[79]\teval-mlogloss:0.23065\n",
      "[80]\teval-mlogloss:0.22893\n",
      "[81]\teval-mlogloss:0.22748\n",
      "[82]\teval-mlogloss:0.22626\n",
      "[83]\teval-mlogloss:0.22495\n",
      "[84]\teval-mlogloss:0.22338\n",
      "[85]\teval-mlogloss:0.22183\n",
      "[86]\teval-mlogloss:0.22079\n",
      "[87]\teval-mlogloss:0.21980\n",
      "[88]\teval-mlogloss:0.21859\n",
      "[89]\teval-mlogloss:0.21717\n",
      "[90]\teval-mlogloss:0.21590\n",
      "[91]\teval-mlogloss:0.21457\n",
      "[92]\teval-mlogloss:0.21346\n",
      "[93]\teval-mlogloss:0.21242\n",
      "[94]\teval-mlogloss:0.21153\n",
      "[95]\teval-mlogloss:0.21042\n",
      "[96]\teval-mlogloss:0.20975\n",
      "[97]\teval-mlogloss:0.20920\n",
      "[98]\teval-mlogloss:0.20772\n",
      "[99]\teval-mlogloss:0.20680\n",
      "[100]\teval-mlogloss:0.20612\n",
      "[101]\teval-mlogloss:0.20498\n",
      "[102]\teval-mlogloss:0.20387\n",
      "[103]\teval-mlogloss:0.20303\n",
      "[104]\teval-mlogloss:0.20271\n",
      "[105]\teval-mlogloss:0.20212\n",
      "[106]\teval-mlogloss:0.20092\n",
      "[107]\teval-mlogloss:0.20022\n",
      "[108]\teval-mlogloss:0.19930\n",
      "[109]\teval-mlogloss:0.19863\n",
      "[110]\teval-mlogloss:0.19801\n",
      "[111]\teval-mlogloss:0.19733\n",
      "[112]\teval-mlogloss:0.19628\n",
      "[113]\teval-mlogloss:0.19603\n",
      "[114]\teval-mlogloss:0.19560\n",
      "[115]\teval-mlogloss:0.19481\n",
      "[116]\teval-mlogloss:0.19442\n",
      "[117]\teval-mlogloss:0.19392\n",
      "[118]\teval-mlogloss:0.19347\n",
      "[119]\teval-mlogloss:0.19263\n",
      "[120]\teval-mlogloss:0.19198\n",
      "[121]\teval-mlogloss:0.19111\n",
      "[122]\teval-mlogloss:0.19067\n",
      "[123]\teval-mlogloss:0.18964\n",
      "[124]\teval-mlogloss:0.18932\n",
      "[125]\teval-mlogloss:0.18853\n",
      "[126]\teval-mlogloss:0.18832\n",
      "[127]\teval-mlogloss:0.18811\n",
      "[128]\teval-mlogloss:0.18783\n",
      "[129]\teval-mlogloss:0.18727\n",
      "[130]\teval-mlogloss:0.18662\n",
      "[131]\teval-mlogloss:0.18634\n",
      "[132]\teval-mlogloss:0.18566\n",
      "[133]\teval-mlogloss:0.18514\n",
      "[134]\teval-mlogloss:0.18492\n",
      "[135]\teval-mlogloss:0.18446\n",
      "[136]\teval-mlogloss:0.18403\n",
      "[137]\teval-mlogloss:0.18390\n",
      "[138]\teval-mlogloss:0.18348\n",
      "[139]\teval-mlogloss:0.18320\n",
      "[140]\teval-mlogloss:0.18284\n",
      "[141]\teval-mlogloss:0.18241\n",
      "[142]\teval-mlogloss:0.18181\n",
      "[143]\teval-mlogloss:0.18143\n",
      "[144]\teval-mlogloss:0.18128\n",
      "[145]\teval-mlogloss:0.18076\n",
      "[146]\teval-mlogloss:0.18023\n",
      "[147]\teval-mlogloss:0.17971\n",
      "[148]\teval-mlogloss:0.17922\n",
      "[149]\teval-mlogloss:0.17866\n",
      "[150]\teval-mlogloss:0.17834\n",
      "[151]\teval-mlogloss:0.17800\n",
      "[152]\teval-mlogloss:0.17760\n",
      "[153]\teval-mlogloss:0.17714\n",
      "[154]\teval-mlogloss:0.17711\n",
      "[155]\teval-mlogloss:0.17624\n",
      "[156]\teval-mlogloss:0.17580\n",
      "[157]\teval-mlogloss:0.17527\n",
      "[158]\teval-mlogloss:0.17527\n",
      "[159]\teval-mlogloss:0.17483\n",
      "[160]\teval-mlogloss:0.17443\n",
      "[161]\teval-mlogloss:0.17427\n",
      "[162]\teval-mlogloss:0.17405\n",
      "[163]\teval-mlogloss:0.17405\n",
      "[164]\teval-mlogloss:0.17386\n",
      "[165]\teval-mlogloss:0.17365\n",
      "[166]\teval-mlogloss:0.17315\n",
      "[167]\teval-mlogloss:0.17302\n",
      "[168]\teval-mlogloss:0.17206\n",
      "[169]\teval-mlogloss:0.17188\n",
      "[170]\teval-mlogloss:0.17160\n",
      "[171]\teval-mlogloss:0.17112\n",
      "[172]\teval-mlogloss:0.17123\n",
      "[173]\teval-mlogloss:0.17118\n",
      "[174]\teval-mlogloss:0.17090\n",
      "[175]\teval-mlogloss:0.17052\n",
      "[176]\teval-mlogloss:0.16996\n",
      "[177]\teval-mlogloss:0.16940\n",
      "[178]\teval-mlogloss:0.16934\n",
      "[179]\teval-mlogloss:0.16898\n",
      "[180]\teval-mlogloss:0.16886\n",
      "[181]\teval-mlogloss:0.16874\n",
      "[182]\teval-mlogloss:0.16832\n",
      "[183]\teval-mlogloss:0.16852\n",
      "[184]\teval-mlogloss:0.16783\n",
      "[185]\teval-mlogloss:0.16767\n",
      "[186]\teval-mlogloss:0.16717\n",
      "[187]\teval-mlogloss:0.16702\n",
      "[188]\teval-mlogloss:0.16655\n",
      "[189]\teval-mlogloss:0.16620\n",
      "[190]\teval-mlogloss:0.16617\n",
      "[191]\teval-mlogloss:0.16636\n",
      "[192]\teval-mlogloss:0.16633\n",
      "[193]\teval-mlogloss:0.16631\n",
      "[194]\teval-mlogloss:0.16626\n",
      "[195]\teval-mlogloss:0.16571\n",
      "[196]\teval-mlogloss:0.16546\n",
      "[197]\teval-mlogloss:0.16556\n",
      "[198]\teval-mlogloss:0.16519\n",
      "[199]\teval-mlogloss:0.16477\n",
      "[200]\teval-mlogloss:0.16468\n",
      "[201]\teval-mlogloss:0.16443\n",
      "[202]\teval-mlogloss:0.16438\n",
      "[203]\teval-mlogloss:0.16436\n",
      "[204]\teval-mlogloss:0.16422\n",
      "[205]\teval-mlogloss:0.16397\n",
      "[206]\teval-mlogloss:0.16375\n",
      "[207]\teval-mlogloss:0.16365\n",
      "[208]\teval-mlogloss:0.16328\n",
      "[209]\teval-mlogloss:0.16323\n",
      "[210]\teval-mlogloss:0.16325\n",
      "[211]\teval-mlogloss:0.16273\n",
      "[212]\teval-mlogloss:0.16263\n",
      "[213]\teval-mlogloss:0.16274\n",
      "[214]\teval-mlogloss:0.16248\n",
      "[215]\teval-mlogloss:0.16207\n",
      "[216]\teval-mlogloss:0.16165\n",
      "[217]\teval-mlogloss:0.16135\n",
      "[218]\teval-mlogloss:0.16095\n",
      "[219]\teval-mlogloss:0.16076\n",
      "[220]\teval-mlogloss:0.16022\n",
      "[221]\teval-mlogloss:0.16004\n",
      "[222]\teval-mlogloss:0.15975\n",
      "[223]\teval-mlogloss:0.15936\n",
      "[224]\teval-mlogloss:0.15928\n",
      "[225]\teval-mlogloss:0.15888\n",
      "[226]\teval-mlogloss:0.15884\n",
      "[227]\teval-mlogloss:0.15897\n",
      "[228]\teval-mlogloss:0.15864\n",
      "[229]\teval-mlogloss:0.15827\n",
      "[230]\teval-mlogloss:0.15817\n",
      "[231]\teval-mlogloss:0.15812\n",
      "[232]\teval-mlogloss:0.15766\n",
      "[233]\teval-mlogloss:0.15714\n",
      "[234]\teval-mlogloss:0.15686\n",
      "[235]\teval-mlogloss:0.15646\n",
      "[236]\teval-mlogloss:0.15633\n",
      "[237]\teval-mlogloss:0.15621\n",
      "[238]\teval-mlogloss:0.15621\n",
      "[239]\teval-mlogloss:0.15621\n",
      "[240]\teval-mlogloss:0.15621\n",
      "[241]\teval-mlogloss:0.15612\n",
      "[242]\teval-mlogloss:0.15590\n",
      "[243]\teval-mlogloss:0.15575\n",
      "[244]\teval-mlogloss:0.15575\n",
      "[245]\teval-mlogloss:0.15576\n",
      "[246]\teval-mlogloss:0.15564\n",
      "[247]\teval-mlogloss:0.15513\n",
      "[248]\teval-mlogloss:0.15497\n",
      "[249]\teval-mlogloss:0.15458\n",
      "[250]\teval-mlogloss:0.15476\n",
      "[251]\teval-mlogloss:0.15475\n",
      "[252]\teval-mlogloss:0.15438\n",
      "[253]\teval-mlogloss:0.15425\n",
      "[254]\teval-mlogloss:0.15399\n",
      "[255]\teval-mlogloss:0.15399\n",
      "[256]\teval-mlogloss:0.15411\n",
      "[257]\teval-mlogloss:0.15398\n",
      "[258]\teval-mlogloss:0.15377\n",
      "[259]\teval-mlogloss:0.15363\n",
      "[260]\teval-mlogloss:0.15372\n",
      "[261]\teval-mlogloss:0.15350\n",
      "[262]\teval-mlogloss:0.15324\n",
      "[263]\teval-mlogloss:0.15305\n",
      "[264]\teval-mlogloss:0.15328\n",
      "[265]\teval-mlogloss:0.15327\n",
      "[266]\teval-mlogloss:0.15323\n",
      "[267]\teval-mlogloss:0.15305\n",
      "[268]\teval-mlogloss:0.15298\n",
      "[269]\teval-mlogloss:0.15268\n",
      "[270]\teval-mlogloss:0.15209\n",
      "[271]\teval-mlogloss:0.15209\n",
      "[272]\teval-mlogloss:0.15211\n",
      "[273]\teval-mlogloss:0.15188\n",
      "[274]\teval-mlogloss:0.15195\n",
      "[275]\teval-mlogloss:0.15153\n",
      "[276]\teval-mlogloss:0.15121\n",
      "[277]\teval-mlogloss:0.15107\n",
      "[278]\teval-mlogloss:0.15119\n",
      "[279]\teval-mlogloss:0.15096\n",
      "[280]\teval-mlogloss:0.15107\n",
      "[281]\teval-mlogloss:0.15106\n",
      "[282]\teval-mlogloss:0.15102\n",
      "[283]\teval-mlogloss:0.15089\n",
      "[284]\teval-mlogloss:0.15099\n",
      "[285]\teval-mlogloss:0.15079\n",
      "[286]\teval-mlogloss:0.15061\n",
      "[287]\teval-mlogloss:0.15065\n",
      "[288]\teval-mlogloss:0.15055\n",
      "[289]\teval-mlogloss:0.15088\n",
      "[290]\teval-mlogloss:0.15081\n",
      "[291]\teval-mlogloss:0.15077\n",
      "[292]\teval-mlogloss:0.15088\n",
      "[293]\teval-mlogloss:0.15087\n",
      "[294]\teval-mlogloss:0.15075\n",
      "[295]\teval-mlogloss:0.15047\n",
      "[296]\teval-mlogloss:0.15027\n",
      "[297]\teval-mlogloss:0.14981\n",
      "[298]\teval-mlogloss:0.14985\n",
      "[299]\teval-mlogloss:0.14979\n",
      "[300]\teval-mlogloss:0.14980\n",
      "[301]\teval-mlogloss:0.14984\n",
      "[302]\teval-mlogloss:0.14954\n",
      "[303]\teval-mlogloss:0.14963\n",
      "[304]\teval-mlogloss:0.14997\n",
      "[305]\teval-mlogloss:0.14962\n",
      "[306]\teval-mlogloss:0.14938\n",
      "[307]\teval-mlogloss:0.14972\n",
      "[308]\teval-mlogloss:0.14944\n",
      "[309]\teval-mlogloss:0.14956\n",
      "[310]\teval-mlogloss:0.14961\n",
      "[311]\teval-mlogloss:0.14953\n",
      "[312]\teval-mlogloss:0.14913\n",
      "[313]\teval-mlogloss:0.14883\n",
      "[314]\teval-mlogloss:0.14896\n",
      "[315]\teval-mlogloss:0.14879\n",
      "[316]\teval-mlogloss:0.14854\n",
      "[317]\teval-mlogloss:0.14850\n",
      "[318]\teval-mlogloss:0.14833\n",
      "[319]\teval-mlogloss:0.14823\n",
      "[320]\teval-mlogloss:0.14822\n",
      "[321]\teval-mlogloss:0.14834\n",
      "[322]\teval-mlogloss:0.14826\n",
      "[323]\teval-mlogloss:0.14813\n",
      "[324]\teval-mlogloss:0.14851\n",
      "[325]\teval-mlogloss:0.14857\n",
      "[326]\teval-mlogloss:0.14857\n",
      "[327]\teval-mlogloss:0.14853\n",
      "[328]\teval-mlogloss:0.14857\n",
      "[329]\teval-mlogloss:0.14837\n",
      "[330]\teval-mlogloss:0.14837\n",
      "[331]\teval-mlogloss:0.14825\n",
      "[332]\teval-mlogloss:0.14802\n",
      "[333]\teval-mlogloss:0.14798\n",
      "[334]\teval-mlogloss:0.14790\n",
      "[335]\teval-mlogloss:0.14769\n",
      "[336]\teval-mlogloss:0.14755\n",
      "[337]\teval-mlogloss:0.14702\n",
      "[338]\teval-mlogloss:0.14691\n",
      "[339]\teval-mlogloss:0.14698\n",
      "[340]\teval-mlogloss:0.14685\n",
      "[341]\teval-mlogloss:0.14693\n",
      "[342]\teval-mlogloss:0.14658\n",
      "[343]\teval-mlogloss:0.14654\n",
      "[344]\teval-mlogloss:0.14650\n",
      "[345]\teval-mlogloss:0.14623\n",
      "[346]\teval-mlogloss:0.14584\n",
      "[347]\teval-mlogloss:0.14588\n",
      "[348]\teval-mlogloss:0.14602\n",
      "[349]\teval-mlogloss:0.14586\n",
      "[350]\teval-mlogloss:0.14579\n",
      "[351]\teval-mlogloss:0.14590\n",
      "[352]\teval-mlogloss:0.14579\n",
      "[353]\teval-mlogloss:0.14520\n",
      "[354]\teval-mlogloss:0.14480\n",
      "[355]\teval-mlogloss:0.14486\n",
      "[356]\teval-mlogloss:0.14467\n",
      "[357]\teval-mlogloss:0.14445\n",
      "[358]\teval-mlogloss:0.14434\n",
      "[359]\teval-mlogloss:0.14403\n",
      "[360]\teval-mlogloss:0.14387\n",
      "[361]\teval-mlogloss:0.14395\n",
      "[362]\teval-mlogloss:0.14377\n",
      "[363]\teval-mlogloss:0.14390\n",
      "[364]\teval-mlogloss:0.14377\n",
      "[365]\teval-mlogloss:0.14376\n",
      "[366]\teval-mlogloss:0.14363\n",
      "[367]\teval-mlogloss:0.14347\n",
      "[368]\teval-mlogloss:0.14342\n",
      "[369]\teval-mlogloss:0.14340\n",
      "[370]\teval-mlogloss:0.14357\n",
      "[371]\teval-mlogloss:0.14330\n",
      "[372]\teval-mlogloss:0.14313\n",
      "[373]\teval-mlogloss:0.14312\n",
      "[374]\teval-mlogloss:0.14314\n",
      "[375]\teval-mlogloss:0.14317\n",
      "[376]\teval-mlogloss:0.14317\n",
      "[377]\teval-mlogloss:0.14315\n",
      "[378]\teval-mlogloss:0.14334\n",
      "[379]\teval-mlogloss:0.14330\n",
      "[380]\teval-mlogloss:0.14332\n",
      "[381]\teval-mlogloss:0.14309\n",
      "[382]\teval-mlogloss:0.14302\n",
      "[383]\teval-mlogloss:0.14287\n",
      "[384]\teval-mlogloss:0.14247\n",
      "[385]\teval-mlogloss:0.14223\n",
      "[386]\teval-mlogloss:0.14252\n",
      "[387]\teval-mlogloss:0.14225\n",
      "[388]\teval-mlogloss:0.14186\n",
      "[389]\teval-mlogloss:0.14174\n",
      "[390]\teval-mlogloss:0.14158\n",
      "[391]\teval-mlogloss:0.14120\n",
      "[392]\teval-mlogloss:0.14134\n",
      "[393]\teval-mlogloss:0.14119\n",
      "[394]\teval-mlogloss:0.14132\n",
      "[395]\teval-mlogloss:0.14125\n",
      "[396]\teval-mlogloss:0.14118\n",
      "[397]\teval-mlogloss:0.14136\n",
      "[398]\teval-mlogloss:0.14125\n",
      "[399]\teval-mlogloss:0.14127\n",
      "[400]\teval-mlogloss:0.14145\n",
      "[401]\teval-mlogloss:0.14156\n",
      "[402]\teval-mlogloss:0.14147\n",
      "[403]\teval-mlogloss:0.14154\n",
      "[404]\teval-mlogloss:0.14103\n",
      "[405]\teval-mlogloss:0.14078\n",
      "[406]\teval-mlogloss:0.14091\n",
      "[407]\teval-mlogloss:0.14086\n",
      "[408]\teval-mlogloss:0.14105\n",
      "[409]\teval-mlogloss:0.14109\n",
      "[410]\teval-mlogloss:0.14066\n",
      "[411]\teval-mlogloss:0.14054\n",
      "[412]\teval-mlogloss:0.14022\n",
      "[413]\teval-mlogloss:0.14036\n",
      "[414]\teval-mlogloss:0.14011\n",
      "[415]\teval-mlogloss:0.13989\n",
      "[416]\teval-mlogloss:0.13988\n",
      "[417]\teval-mlogloss:0.13957\n",
      "[418]\teval-mlogloss:0.13942\n",
      "[419]\teval-mlogloss:0.13932\n",
      "[420]\teval-mlogloss:0.13946\n",
      "[421]\teval-mlogloss:0.13935\n",
      "[422]\teval-mlogloss:0.13944\n",
      "[423]\teval-mlogloss:0.13962\n",
      "[424]\teval-mlogloss:0.13960\n",
      "[425]\teval-mlogloss:0.13975\n",
      "[426]\teval-mlogloss:0.13991\n",
      "[427]\teval-mlogloss:0.13997\n",
      "[428]\teval-mlogloss:0.13972\n",
      "[429]\teval-mlogloss:0.13968\n",
      "[430]\teval-mlogloss:0.13975\n",
      "[431]\teval-mlogloss:0.13981\n",
      "[432]\teval-mlogloss:0.13974\n",
      "[433]\teval-mlogloss:0.13973\n",
      "[434]\teval-mlogloss:0.13977\n",
      "[435]\teval-mlogloss:0.13955\n",
      "[436]\teval-mlogloss:0.13930\n",
      "[437]\teval-mlogloss:0.13912\n",
      "[438]\teval-mlogloss:0.13896\n",
      "[439]\teval-mlogloss:0.13883\n",
      "[440]\teval-mlogloss:0.13904\n",
      "[441]\teval-mlogloss:0.13917\n",
      "[442]\teval-mlogloss:0.13909\n",
      "[443]\teval-mlogloss:0.13938\n",
      "[444]\teval-mlogloss:0.13915\n",
      "[445]\teval-mlogloss:0.13920\n",
      "[446]\teval-mlogloss:0.13906\n",
      "[447]\teval-mlogloss:0.13886\n",
      "[448]\teval-mlogloss:0.13872\n",
      "[449]\teval-mlogloss:0.13866\n",
      "[450]\teval-mlogloss:0.13857\n",
      "[451]\teval-mlogloss:0.13880\n",
      "[452]\teval-mlogloss:0.13880\n",
      "[453]\teval-mlogloss:0.13869\n",
      "[454]\teval-mlogloss:0.13850\n",
      "[455]\teval-mlogloss:0.13842\n",
      "[456]\teval-mlogloss:0.13819\n",
      "[457]\teval-mlogloss:0.13813\n",
      "[458]\teval-mlogloss:0.13805\n",
      "[459]\teval-mlogloss:0.13821\n",
      "[460]\teval-mlogloss:0.13853\n",
      "[461]\teval-mlogloss:0.13854\n",
      "[462]\teval-mlogloss:0.13846\n",
      "[463]\teval-mlogloss:0.13842\n",
      "[464]\teval-mlogloss:0.13819\n",
      "[465]\teval-mlogloss:0.13798\n",
      "[466]\teval-mlogloss:0.13826\n",
      "[467]\teval-mlogloss:0.13839\n",
      "[468]\teval-mlogloss:0.13843\n",
      "[469]\teval-mlogloss:0.13830\n",
      "[470]\teval-mlogloss:0.13812\n",
      "[471]\teval-mlogloss:0.13814\n",
      "[472]\teval-mlogloss:0.13819\n",
      "[473]\teval-mlogloss:0.13804\n",
      "[474]\teval-mlogloss:0.13769\n",
      "[475]\teval-mlogloss:0.13779\n",
      "[476]\teval-mlogloss:0.13729\n",
      "[477]\teval-mlogloss:0.13713\n",
      "[478]\teval-mlogloss:0.13724\n",
      "[479]\teval-mlogloss:0.13717\n",
      "[480]\teval-mlogloss:0.13715\n",
      "[481]\teval-mlogloss:0.13691\n",
      "[482]\teval-mlogloss:0.13663\n",
      "[483]\teval-mlogloss:0.13671\n",
      "[484]\teval-mlogloss:0.13674\n",
      "[485]\teval-mlogloss:0.13685\n",
      "[486]\teval-mlogloss:0.13715\n",
      "[487]\teval-mlogloss:0.13703\n",
      "[488]\teval-mlogloss:0.13700\n",
      "[489]\teval-mlogloss:0.13702\n",
      "[490]\teval-mlogloss:0.13696\n",
      "[491]\teval-mlogloss:0.13680\n",
      "[492]\teval-mlogloss:0.13652\n",
      "[493]\teval-mlogloss:0.13637\n",
      "[494]\teval-mlogloss:0.13627\n",
      "[495]\teval-mlogloss:0.13603\n",
      "[496]\teval-mlogloss:0.13595\n",
      "[497]\teval-mlogloss:0.13603\n",
      "[498]\teval-mlogloss:0.13578\n",
      "[499]\teval-mlogloss:0.13597\n"
     ]
    }
   ],
   "source": [
    "# Convert to DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(train_images, label=train_labels)\n",
    "dtest = xgb.DMatrix(test_images, label=test_labels)\n",
    "\n",
    "# Set up parameters for XGBoost\n",
    "param = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 10,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'subsample': 0.0166\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_round = 500\n",
    "evallist  = [(dtrain, 'eval'), (dtest, 'eval')]\n",
    "bst = xgb.train(param, dtrain, num_round, evals=evallist, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.72%\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, preds)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
